Matrix, ale na serio: naukowiec Eliezer Yudkowski przestrzega przed sytuacją, w której maszyny zwrócą się przeciwko nam.

Ludzie wymyślili sztuczną inteligencję, jednak maszyny wyrwały się spod ich kontroli i zwróciły się przeciwko twórcom. Aby odciąć je od energii słonecznej, ludzie spowili niebo czarnym smogiem. Ta decyzja okazała się fatalna w skutkach – maszyny jako źródło energii wybrały ludzi, więżąc ich w programie zwanym Matriksem, symulującym świat z roku 1999... Brzmi znajomo? Ten opis to punkt wyjścia pierwszego Matrixa, przez lata uchodzącego za science-fiction, które nie ma prawa się wydarzyć. Oh, wait...

Globalny dyskurs o tym, że AI rozwija się szybciej niż przypuszczaliśmy, nasila się z tygodnia na tydzień, a kolejną z osób, które postanowiły zabrać w tej sprawie głos jest Eliezer Yudkowski, amerykański badacz sztucznej inteligencji, pisarz science-fiction i współtwórca think tanku Machine Intelligence Research Institute. Yudkowski wystosował w tej sprawie otwarty list do... wszystkich. I opublikował go na łamach magazynu Time. Ostrzegamy – nie jest to lektura dla ludzi o słabych nerwach. Co prawda warto przy tym pamiętać, że naukowiec jest od wielu lat orędownikiem teorii przyjaznej sztucznej inteligencji, zakładającej że AI musi dążyć do tego, by swoją działalnością nie przysparzać nikomu cierpienia – dla wielu innych badaczy ciut utopijnej; stąd jego obawy o rozwój technologii. Ale i tak list trąci apokalipsą.